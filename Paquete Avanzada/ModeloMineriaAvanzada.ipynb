{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fGfAaC9dUfO"
      },
      "source": [
        "**LEAD University - Minería de datos**\n",
        "\n",
        "Python Project\n",
        "\n",
        "**Contributors**\n",
        "- Carolina Salas Moreno\n",
        "- Deykel Bernard Salazar\n",
        "- Esteban Ramirez Montano\n",
        "- Kristhel Porras Mata\n",
        "- Marla Gomez Hernández\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pxx9r1xc-1c"
      },
      "source": [
        "## Requirements\n",
        "**Step 1:** Please install Microsoft C++ Build Tools in your machine.\n",
        "\n",
        "**Step 2:** Install Python 3.11.7\n",
        "\n",
        "**Step 3:** Run the following code if this is your first time running it `pip install -r requirements.txt`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZXUiJAacFRT"
      },
      "source": [
        "# Importar las librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dQw57BLb3dFh"
      },
      "outputs": [],
      "source": [
        "# Main Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import umap.umap_ as umap\n",
        "\n",
        "# Data Optimization\n",
        "from sklearn_genetic import GASearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectFromModel \n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn_genetic.space import Integer, Categorical, Continuous\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "#Feature Selection\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LassoCV \n",
        "\n",
        "# Clustering Libraries\n",
        "from abc import ABCMeta, abstractmethod\n",
        "from scipy.cluster.hierarchy import dendrogram, ward, single, complete, average, linkage, fcluster\n",
        "from sklearn.cluster import KMeans\n",
        "from pyclustering.cluster.kmedoids import kmedoids\n",
        "\n",
        "# Dimensionality Reduction\n",
        "from prince import PCA as PCA_Prince\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Evaluation Metrics\n",
        "from sklearn.metrics import silhouette_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Regression Models\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "\n",
        "# Classification Models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor\n",
        "\n",
        "# Additional Tools\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScX-De7IdB7L"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HIssRCV8cKBa"
      },
      "outputs": [],
      "source": [
        "# Análisis Exploratorio de Datos (EDA)\n",
        "class EDA:\n",
        "    def __init__(self, file=None):\n",
        "        \"\"\"\n",
        "        Inicializa la clase EDA y carga datos desde un archivo CSV si se proporciona.\n",
        "\n",
        "        Parámetros:\n",
        "            file (str): Ruta al archivo CSV. Si no se proporciona, se inicializa un DataFrame vacío.\n",
        "        \"\"\"\n",
        "        self.__df = pd.read_csv(file) if file else pd.DataFrame()\n",
        "\n",
        "    def head_df(self, n=5):\n",
        "        return self.__df.head(n) if not self.__df.empty else \"No se cargaron los datos :(\"\n",
        "\n",
        "    def tail_df(self, n=5):\n",
        "        return self.__df.tail(n) if not self.__df.empty else \"No se cargaron los datos :(\"\n",
        "\n",
        "    def check_data_types(self):\n",
        "        return self.__df.dtypes\n",
        "\n",
        "    def drop_irrelevant_columns(self, columns):\n",
        "        self.__df.drop(columns=columns, inplace=True)\n",
        "\n",
        "    def drop_missing_values(self):\n",
        "        self.__df.dropna(inplace=True)\n",
        "\n",
        "    def detect_outliers(self):\n",
        "        num_df = self.__df.select_dtypes(include=['float64', 'int64'])\n",
        "        if num_df.empty:\n",
        "            return \"No hay columnas numéricas en el DataFrame.\"\n",
        "\n",
        "        Q1 = num_df.quantile(0.25)\n",
        "        Q3 = num_df.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        outliers = ((num_df < (Q1 - 1.5 * IQR)) | (num_df > (Q3 + 1.5 * IQR))).sum()\n",
        "        Dicc_outliers = {col: outliers[col] for col in num_df.columns if outliers[col] > 0}\n",
        "\n",
        "        return Dicc_outliers if Dicc_outliers else \"No se detectaron valores atípicos en las columnas numéricas.\"\n",
        "\n",
        "    def plot_scatter(self, col1, col2):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.scatterplot(x=self.__df[col1], y=self.__df[col2])\n",
        "        plt.title(f'Gráfico de Dispersión: {col1} vs {col2}')\n",
        "        plt.xlabel(col1)\n",
        "        plt.ylabel(col2)\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_histogram(self, col):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.histplot(self.__df[col], kde=True)\n",
        "        plt.title(f'Histograma de {col}')\n",
        "        plt.xlabel(col)\n",
        "        plt.ylabel('Frecuencia')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_heatmap(self):\n",
        "        num_df = self.__df.select_dtypes(include=['float64', 'int64'])\n",
        "        if num_df.empty:\n",
        "            return \"No hay columnas numéricas para generar el mapa de calor.\"\n",
        "\n",
        "        num_df = num_df.loc[:, num_df.apply(lambda x: np.std(x) > 0.01)]\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        sns.heatmap(num_df.corr(), cmap=\"coolwarm\", annot= True, linewidths=0.5, cbar=True) #annot=False es para que no se vean los numeros en los cuadros\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.title(\"Correlation heatmap\", fontsize=18)\n",
        "        plt.ion()\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Clase EDA - DataFrame de la forma: {self.__df.shape}\"\n",
        "\n",
        "    def get_df(self):\n",
        "        \"\"\"Devuelve una copia del df para que las familias de los algoritmos las utilicen\"\"\"\n",
        "        return self.__df.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataOptimization(EDA):\n",
        "    def __init__(self, datos_eda):\n",
        "        \"\"\"\n",
        "        Use the processed DataFrame from EDA to optimize models.\n",
        "\n",
        "        Parameters:\n",
        "        - datos_eda: This is the processed DataFrame from the EDA class.\n",
        "        \"\"\"\n",
        "        self.__df = datos_eda.get_df()\n",
        "        \n",
        "        # Data components\n",
        "        self.X_train = None\n",
        "        self.X_test = None\n",
        "        self.y_train = None\n",
        "        self.y_test = None\n",
        "        \n",
        "        # Models to evaluate\n",
        "        self.models = {\n",
        "            'LinearRegression': LinearRegression(),\n",
        "            'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
        "            'RandomForestRegressor': RandomForestRegressor(),\n",
        "            'Lasso': Lasso(),\n",
        "            'Ridge': Ridge(),\n",
        "            'KNeighborsRegressor': KNeighborsRegressor(),\n",
        "            'XGBRegressor': XGBRegressor(random_state=42)\n",
        "        }\n",
        "\n",
        "        self.param_grids_genetic = self._get_param_grids_genetic()\n",
        "        self.param_grids_exhaustive = self._get_param_grids_exhaustive()\n",
        "\n",
        "#------------------------Data Split Components--------------------------------------------------------------\n",
        "\n",
        "    def split_df(self, target_column, test_size=None, random_state=42):\n",
        "        \"\"\"\n",
        "        Splits the dataframe into training and test sets.\n",
        "\n",
        "        Parameters:\n",
        "        - target_column: str -> Name of the target column (y).\n",
        "        - test_size: float -> Proportion of the test set (if not provided, it is calculated from the entered percentage).\n",
        "        - random_state: int -> Seed for randomization.\n",
        "\n",
        "        Returns:\n",
        "        - X_train, X_test, y_train, y_test: Split and preprocessed datasets.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            try:\n",
        "                percent = float(input(\"Enter the percentage for the training set: (Example: 80) \\n\"))\n",
        "                if 0 < percent < 100:\n",
        "                    train_size = percent / 100\n",
        "                    break # Exit the loop\n",
        "                else:\n",
        "                    print(\"The percentage must be between 1 and 99.\")\n",
        "            except ValueError:\n",
        "                print(\"Invalid number. Try again.\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                # Separate features (X) and target variable (y)\n",
        "                X = self.__df.drop(columns=[target_column])\n",
        "                y = self.__df[target_column]\n",
        "                break  # Exit the loop if there are no errors\n",
        "            except KeyError:\n",
        "                print(f\"The column '{target_column}' does not exist. Try again.\")\n",
        "                print(\"Available columns:\")\n",
        "                print(self.check_data_types())\n",
        "                target_column = input(\"Enter the correct name of the target column: \")\n",
        "\n",
        "        # Preprocess features (X), convert categorical variables to One-Hot Encoding\n",
        "        import pandas as pd\n",
        "        X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "        # Check if the target variable (y) is categorical and needs encoding\n",
        "        if y.dtypes == 'object' or y.dtypes.name == 'category':\n",
        "            from sklearn.preprocessing import LabelEncoder\n",
        "            le = LabelEncoder()\n",
        "            y = le.fit_transform(y)\n",
        "\n",
        "        # Perform the split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size= 1 - train_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        print(f\"Data split:\\n- Training: {X_train.shape[0]} rows\\n- Test: {X_test.shape[0]} rows\")\n",
        "        return X_train, X_test, y_train, y_test\n",
        "    \n",
        "#------------------------Genectic Search Components--------------------------------------------------------------\n",
        "\n",
        "    def _get_param_grids_genetic(self):\n",
        "        \"\"\"Defines the parameters used for each algorithm in the genetic search.\"\"\"\n",
        "        return {\n",
        "            'LinearRegression': {\n",
        "                \"clf__copy_X\": Categorical([True, False]),\n",
        "                \"clf__fit_intercept\": Categorical([True, False]),\n",
        "                \"clf__positive\": Categorical([True, False])\n",
        "            },\n",
        "            'DecisionTreeRegressor': {\n",
        "                \"clf__max_depth\": Integer(3, 10),\n",
        "                'clf__min_samples_split': Integer(2, 10),\n",
        "                'clf__min_samples_leaf': Integer(1, 4),\n",
        "                'clf__random_state': Categorical([42])\n",
        "            },\n",
        "            'RandomForestRegressor': {\n",
        "                \"clf__n_estimators\": Integer(50, 100),\n",
        "                \"clf__max_depth\": Integer(5, 10),\n",
        "                'clf__min_samples_split': Integer(2, 5),\n",
        "                'clf__random_state': Categorical([42])\n",
        "            },\n",
        "            'Lasso': {\n",
        "                'clf__alpha': Continuous(1.0, 1.0),\n",
        "                'clf__fit_intercept': Categorical([True, False]),\n",
        "                'clf__max_iter': Integer(1000, 2000),\n",
        "                'clf__tol': Continuous(0.0001, 0.001),\n",
        "                'clf__selection': Categorical(['cyclic', 'random'])\n",
        "            },\n",
        "            'Ridge': {\n",
        "                'clf__alpha': Continuous(1.0, 1.0),\n",
        "                'clf__fit_intercept': Categorical([True, False]),\n",
        "                'clf__tol': Continuous(0.0001, 0.001),\n",
        "                'clf__solver': Categorical(['auto', 'svd', 'cholesky'])\n",
        "            },\n",
        "            'KNeighborsRegressor': {\n",
        "                'clf__n_neighbors': Integer(3, 7),\n",
        "                'clf__weights': Categorical(['uniform', 'distance']),\n",
        "                'clf__algorithm': Categorical(['auto', 'ball_tree', 'kd_tree'])\n",
        "            },\n",
        "            'XGBRegressor': {\n",
        "                'clf__learning_rate': Continuous(0.01, 0.1),\n",
        "                'clf__n_estimators': Integer(50, 100),\n",
        "                'clf__max_depth': Integer(3, 5),\n",
        "                'clf__subsample': Continuous(0.8, 1.0),\n",
        "                'clf__colsample_bytree': Continuous(0.8, 1.0)\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def genetic_search(self):\n",
        "        \"\"\"\n",
        "        Optimize regression models using genetic algorithms.\n",
        "        \"\"\"\n",
        "\n",
        "        # Eliminar este if despues del testing ERM\n",
        "        if self.X_train is None or self.X_test is None:\n",
        "            print(\"Error: Debes ejecutar split_df() antes de llamar a genetic_search().\")\n",
        "            return\n",
        "\n",
        "        results = {}\n",
        "        \n",
        "        # Feature selection\n",
        "        lasso_cv = LassoCV(cv=5) \n",
        "        lasso_cv.fit(self.X_train, self.y_train)\n",
        "        f_selection = SelectFromModel(lasso_cv)\n",
        "\n",
        "        '''modelo_base_rfe = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        rfe = RFE(modelo_base_rfe, n_features_to_select=n_features)\n",
        "        X_rfe_selected = rfe.fit_transform(self.X_selected, self.y)\n",
        "        self.selected_features_rfe = self.X_selected.columns[rfe.support_]\n",
        "        self.X_selected = self.X_selected[self.selected_features_rfe]\n",
        "        print(f\"Características finales seleccionadas por RFE: {list(self.selected_features_rfe)}\")'''\n",
        "\n",
        "        self.X_train = f_selection.transform(self.X_train)\n",
        "        self.X_test = f_selection.transform(self.X_test)\n",
        "\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            pl = Pipeline([\n",
        "              ('fs', f_selection), \n",
        "              ('clf', model), \n",
        "            ])            \n",
        "            print(f\"Entrenando {name} con método genético...\")\n",
        "            evolved_estimator = GASearchCV(\n",
        "                estimator=pl,\n",
        "                cv=5,\n",
        "                scoring=\"neg_mean_squared_error\",\n",
        "                population_size=10,\n",
        "                generations=5,\n",
        "                tournament_size=3,\n",
        "                elitism=True,\n",
        "                crossover_probability=0.8,\n",
        "                mutation_probability=0.1,\n",
        "                param_grid=self.param_grids_genetic[name],\n",
        "                algorithm=\"eaSimple\",\n",
        "                n_jobs=-1,\n",
        "                error_score='raise',\n",
        "                verbose=True\n",
        "            )\n",
        "            evolved_estimator.fit(self.X_train, self.y_train)\n",
        "            results[name] = {\n",
        "                'best_params': evolved_estimator.best_params_,\n",
        "                'estimator': evolved_estimator.best_estimator_\n",
        "            }\n",
        "        return results\n",
        "\n",
        "#------------------------Exhaustive Search Components--------------------------------------------------------------\n",
        "\n",
        "    def _get_param_grids_exhaustive(self):\n",
        "        \"\"\"Defines the parameters used for each algorithm in the exhaustive search.\"\"\"\n",
        "        return {\n",
        "            \n",
        "            'LinearRegression': {\n",
        "                \"clf__copy_X\": [True, False],\n",
        "                \"clf__fit_intercept\": [True, False],\n",
        "                \"clf__positive\": [True, False]\n",
        "            },\n",
        "            'DecisionTreeRegressor': {\n",
        "                \"clf__max_depth\": [3, 5, 7, 10],\n",
        "                'clf__min_samples_split': [2, 5, 10],\n",
        "                'clf__min_samples_leaf': [1, 2, 4],\n",
        "                'clf__random_state': [42]\n",
        "            },\n",
        "            'RandomForestRegressor': {\n",
        "                \"clf__n_estimators\": [50, 100],\n",
        "                \"clf__max_depth\": [5, 10],\n",
        "                'clf__min_samples_split': [2, 5],\n",
        "                'clf__random_state': [42]\n",
        "            },\n",
        "            'Lasso': {\n",
        "                'clf__alpha': [1.0],\n",
        "                'clf__fit_intercept': [True, False],\n",
        "                'clf__max_iter': [1000, 2000],\n",
        "                'clf__tol': [0.0001, 0.001],\n",
        "                'clf__selection': ['cyclic', 'random']\n",
        "            },\n",
        "            'Ridge': {\n",
        "                'clf__alpha': [1.0],\n",
        "                'clf__fit_intercept': [True, False],\n",
        "                'clf__tol': [0.0001, 0.001],\n",
        "                'clf__solver': ['auto', 'svd', 'cholesky']\n",
        "            },\n",
        "            'KNeighborsRegressor': {\n",
        "                'clf__n_neighbors': [3, 5, 7],\n",
        "                'clf__weights': ['uniform', 'distance'],\n",
        "                'clf__algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
        "            },\n",
        "            'XGBRegressor': {\n",
        "                'clf__learning_rate': [0.01, 0.1],\n",
        "                'clf__n_estimators': [50, 100],\n",
        "                'clf__max_depth': [3, 5],\n",
        "                'clf__subsample': [0.8, 1.0],\n",
        "                'clf__colsample_bytree': [0.8, 1.0]\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def exhaustive_search(self):\n",
        "        \"\"\"\n",
        "        Solves optimization problems by creating a population or group of possible solutions to the problem.\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "        lasso_cv = LassoCV(cv=5) \n",
        "        lasso_cv.fit(self.X_train, self.y_train)\n",
        "        f_selection = SelectFromModel(lasso_cv)\n",
        "        self.X_train = f_selection.transform(self.X_train)\n",
        "        self.X_test = f_selection.transform(self.X_test)\n",
        "        for name, model in self.models.items():\n",
        "            \n",
        "            pl = Pipeline([\n",
        "              ('clf', model), \n",
        "            ])\n",
        "            print(f\"Entrenando {name} con método exhaustivo...\")\n",
        "            grid_search = GridSearchCV(\n",
        "                estimator=pl,\n",
        "                param_grid=self.param_grids_exhaustive[name],\n",
        "                cv=5,\n",
        "                scoring='neg_mean_squared_error',\n",
        "                n_jobs=-1,\n",
        "                verbose=1\n",
        "            )\n",
        "            grid_search.fit(self.X_train, self.y_train)\n",
        "            results[name] = {\n",
        "                'best_params': grid_search.best_params_,\n",
        "                'estimator': grid_search.best_estimator_\n",
        "            }\n",
        "        return results\n",
        "    \n",
        "#------------------------Director Function--------------------------------------------------------------\n",
        "    \n",
        "    def opti_director(self, target_column, method='both', random_state=42):\n",
        "        \"\"\"\n",
        "        This method orchestrates the optimization process for every model in this class.\n",
        "        1. Make the data split\n",
        "        2. Performs the optimization of models (genetic, exhaustive or both)\n",
        "        3. Extract the best parameters in a clean format to use them in the models.\n",
        "        \n",
        "        Parameters:\n",
        "        - target_column: str -> Name of the target column (y).\n",
        "        - method: str -> What optimization method is going to be used (genetic, exhaustive or both)\n",
        "        - test_size: float -> Percentage of the test set.\n",
        "        - random_state: int -> Random seed for reproducibility.\n",
        "        \n",
        "        Returns:\n",
        "        - dict -> Keeps the best parameters for each model.\n",
        "        \"\"\"\n",
        "        #1. Make the data split\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = self.split_df(\n",
        "        target_column=target_column,\n",
        "        random_state=random_state\n",
        "        )\n",
        "        \n",
        "        # 2. Performs the optimization of models (genetic, exhaustive or both)\n",
        "        best_params = {}\n",
        "        \n",
        "        if method.lower() == 'genetic' or method.lower() == 'both':\n",
        "            print(\"\\n=== Iniciando búsqueda genética ===\")\n",
        "            genetic_results = self.genetic_search()\n",
        "            \n",
        "            # 3. Extract the best parameters in a clean format to use them in the models.\n",
        "            clean_genetic_params = {}\n",
        "            for model_name, model_result in genetic_results.items():\n",
        "                best_params_model = model_result['best_params']\n",
        "                model_params = {param.replace('clf__', ''): value for param, value in best_params_model.items()}\n",
        "                clean_genetic_params[model_name] = model_params\n",
        "            \n",
        "            best_params['genetic'] = clean_genetic_params\n",
        "            \n",
        "        if method.lower() == 'exhaustive' or method.lower() == 'both':\n",
        "            print(\"\\n=== Iniciando búsqueda exhaustiva ===\")\n",
        "            exhaustive_results = self.exhaustive_search()\n",
        "            \n",
        "            # 3. Extract the best parameters in a clean format to use them in the models.\n",
        "            clean_exhaustive_params = {}\n",
        "            for model_name, model_result in exhaustive_results.items():\n",
        "                best_params_model = model_result['best_params']\n",
        "                model_params = {param.replace('clf__', ''): value for param, value in best_params_model.items()}\n",
        "                clean_exhaustive_params[model_name] = model_params\n",
        "            \n",
        "            best_params['exhaustive'] = clean_exhaustive_params\n",
        "        \n",
        "        return best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Unnamed: 0         ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
            "0           4   8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
            "1           5   9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
            "2           6   5.584087  188.313324  28748.687739     7.544869  326.678363   \n",
            "3           7  10.223862  248.071735  28749.716544     7.513408  393.663396   \n",
            "4           8   8.635849  203.361523  13672.091764     4.563009  303.309771   \n",
            "\n",
            "   Conductivity  Organic_carbon  Trihalomethanes  Turbidity Potability  \n",
            "0    363.266516       18.436524       100.341674   4.628771         No  \n",
            "1    398.410813       11.558279        31.997993   4.075075         No  \n",
            "2    280.467916        8.399735        54.917862   2.559708         No  \n",
            "3    283.651634       13.789695        84.603556   2.672989         No  \n",
            "4    474.607645       12.363817        62.798309   4.401425         No  \n",
            "Data split:\n",
            "- Training: 1407 rows\n",
            "- Test: 604 rows\n",
            "\n",
            "=== Iniciando búsqueda genética ===\n",
            "Entrenando LinearRegression con método genético...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\esteb\\Documents\\GitHub\\MineriaAvanzada\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\esteb\\Documents\\GitHub\\MineriaAvanzada\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gen\tnevals\tfitness  \tfitness_std\tfitness_max\tfitness_min\n",
            "0  \t10    \t-0.239295\t0.00213185 \t-0.237549  \t-0.24191   \n",
            "1  \t6     \t-0.237987\t0.00130592 \t-0.237549  \t-0.241905  \n",
            "2  \t7     \t-0.237551\t3.87778e-06\t-0.237549  \t-0.237559  \n",
            "3  \t7     \t-0.23755 \t2.90833e-06\t-0.237549  \t-0.237559  \n",
            "4  \t4     \t-0.237549\t2.77556e-17\t-0.237549  \t-0.237549  \n",
            "5  \t8     \t-0.237549\t2.77556e-17\t-0.237549  \t-0.237549  \n",
            "Entrenando DecisionTreeRegressor con método genético...\n",
            "gen\tnevals\tfitness  \tfitness_std\tfitness_max\tfitness_min\n",
            "0  \t10    \t-0.139649\t0.0291812  \t-0.106154  \t-0.194121  \n",
            "1  \t6     \t-0.106154\t0          \t-0.106154  \t-0.106154  \n",
            "2  \t8     \t-0.106154\t0          \t-0.106154  \t-0.106154  \n",
            "3  \t8     \t-0.106154\t0          \t-0.106154  \t-0.106154  \n",
            "4  \t6     \t-0.106154\t0          \t-0.106154  \t-0.106154  \n",
            "5  \t7     \t-0.106154\t0          \t-0.106154  \t-0.106154  \n",
            "Entrenando RandomForestRegressor con método genético...\n",
            "gen\tnevals\tfitness  \tfitness_std\tfitness_max\tfitness_min\n",
            "0  \t10    \t-0.100836\t0.028193   \t-0.0590256 \t-0.134795  \n",
            "1  \t7     \t-0.0706256\t0.0174249  \t-0.0585015 \t-0.110537  \n",
            "2  \t6     \t-0.060141 \t0.00377848 \t-0.0585015 \t-0.0714246 \n",
            "3  \t6     \t-0.058766 \t0.000445726\t-0.0585015 \t-0.0599564 \n",
            "4  \t8     \t-0.058516 \t4.23752e-05\t-0.0585015 \t-0.0586431 \n",
            "5  \t5     \t-0.0675927\t0.0272637  \t-0.0585015 \t-0.149384  \n",
            "Entrenando Lasso con método genético...\n",
            "gen\tnevals\tfitness  \tfitness_std\tfitness_max\tfitness_min\n",
            "0  \t10    \t-0.240523\t0.00237534 \t-0.237609  \t-0.24248   \n",
            "1  \t8     \t-0.239066\t0.00221849 \t-0.237609  \t-0.242465  \n",
            "2  \t6     \t-0.238097\t0.00145119 \t-0.237609  \t-0.24245   \n",
            "3  \t5     \t-0.237612\t4.1022e-06 \t-0.237609  \t-0.237622  \n",
            "4  \t7     \t-0.237609\t0          \t-0.237609  \t-0.237609  \n",
            "5  \t7     \t-0.237611\t2.43802e-06\t-0.237609  \t-0.237616  \n",
            "Entrenando Ridge con método genético...\n",
            "gen\tnevals\tfitness  \tfitness_std\tfitness_max\tfitness_min\n",
            "0  \t10    \t-0.239734\t0.00217525 \t-0.237559  \t-0.24191   \n",
            "1  \t8     \t-0.237994\t0.00130515 \t-0.237559  \t-0.24191   \n",
            "2  \t6     \t-0.237559\t0          \t-0.237559  \t-0.237559  \n",
            "3  \t4     \t-0.237559\t0          \t-0.237559  \t-0.237559  \n",
            "4  \t4     \t-0.237559\t0          \t-0.237559  \t-0.237559  \n",
            "5  \t6     \t-0.237559\t0          \t-0.237559  \t-0.237559  \n",
            "Entrenando KNeighborsRegressor con método genético...\n",
            "gen\tnevals\tfitness   \tfitness_std\tfitness_max\tfitness_min\n",
            "0  \t10    \t-0.0410876\t0.00187463 \t-0.0384923 \t-0.0435984 \n",
            "1  \t4     \t-0.0392534\t0.00140708 \t-0.0384923 \t-0.0420616 \n",
            "2  \t6     \t-0.0384923\t6.93889e-18\t-0.0384923 \t-0.0384923 \n",
            "3  \t6     \t-0.0384923\t6.93889e-18\t-0.0384923 \t-0.0384923 \n",
            "4  \t6     \t-0.0384923\t6.93889e-18\t-0.0384923 \t-0.0384923 \n",
            "5  \t6     \t-0.0384923\t6.93889e-18\t-0.0384923 \t-0.0384923 \n",
            "Entrenando XGBRegressor con método genético...\n",
            "gen\tnevals\tfitness   \tfitness_std\tfitness_max\tfitness_min\n",
            "0  \t10    \t-0.0730908\t0.0545664  \t-0.0166559 \t-0.18257   \n",
            "1  \t6     \t-0.0241451\t0.0104376  \t-0.0166559 \t-0.0415594 \n",
            "2  \t8     \t-0.0166692\t3.97419e-05\t-0.0166559 \t-0.0167884 \n",
            "3  \t6     \t-0.0166573\t4.27075e-06\t-0.0166559 \t-0.0166701 \n",
            "4  \t8     \t-0.0166559\t3.46945e-18\t-0.0166559 \t-0.0166559 \n",
            "5  \t7     \t-0.0167028\t0.000140753\t-0.0166559 \t-0.0171251 \n"
          ]
        }
      ],
      "source": [
        "# MI TESTING\n",
        "archivo_csv = \"../dataset/potabilidad_V2.csv\"\n",
        "eda = EDA(file=archivo_csv)\n",
        "print(eda.head_df())\n",
        "optimizador = DataOptimization(eda)\n",
        "\n",
        "best_params = optimizador.opti_director(\n",
        "    target_column='Potability',\n",
        "    method='genetic',             \n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHJDmyoocftY"
      },
      "outputs": [],
      "source": [
        "class NoSupervisado(EDA):\n",
        "    def __init__(self, datos_eda):\n",
        "        # La clase ya utiliza el df procesado en la clase EDA\n",
        "        df = datos_eda.get_df()\n",
        "        super().__init__()\n",
        "        self.__df = df\n",
        "\n",
        "    @property\n",
        "    def df(self):\n",
        "        return self.__df\n",
        "\n",
        "    @df.setter\n",
        "    def df(self, p_df):\n",
        "        self.__df = p_df\n",
        "\n",
        "    def __byebye_object_values(self):\n",
        "        # Elimina columnas de tipo 'object'\n",
        "        self.__df = self.__df.select_dtypes(exclude=['object'])\n",
        "\n",
        "    def calcular_metricas(self, labels):\n",
        "        \"\"\"\n",
        "        Calcula métricas de evaluación para clustering.\n",
        "        \"\"\"\n",
        "        data = self.__df.dropna()\n",
        "        data = (data - data.mean()) / data.std()\n",
        "        metrics = {\n",
        "            \"Índice de Silueta\": silhouette_score(data, labels),\n",
        "            \"Calinski-Harabasz\": calinski_harabasz_score(data, labels),\n",
        "            \"Davies-Bouldin\": davies_bouldin_score(data, labels)\n",
        "        }\n",
        "        return metrics\n",
        "\n",
        "    def kmeans(self, n_clusters):\n",
        "        self.__byebye_object_values()\n",
        "        data = self.__df\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "        labels = kmeans.fit_predict(data)\n",
        "        metrics = self.calcular_metricas(labels)\n",
        "        print(f\"Métricas para K-Means (n_clusters={n_clusters}): {metrics}\")\n",
        "        return metrics\n",
        "\n",
        "    def k_medoids(self, n_clusters, metric='euclidean'):\n",
        "        self.__byebye_object_values()\n",
        "        data = self.__df\n",
        "        \n",
        "        # Convertir a numpy array si aún no lo es\n",
        "        data_array = np.array(data)\n",
        "        \n",
        "        # Inicialización de medoides (seleccionar índices aleatorios)\n",
        "        np.random.seed(42)  # Para reproducibilidad\n",
        "        initial_medoids = np.random.choice(len(data_array), n_clusters, replace=False).tolist()\n",
        "        \n",
        "        # Crear y ejecutar el algoritmo KMedoids\n",
        "        kmedoids_instance = kmedoids(data_array, initial_medoids)\n",
        "        kmedoids_instance.process()\n",
        "        \n",
        "        # Obtener clusters y medoides\n",
        "        clusters = kmedoids_instance.get_clusters()  # Lista de listas de índices\n",
        "        medoids = kmedoids_instance.get_medoids()    # Lista de índices de medoides\n",
        "        \n",
        "        # Crear etiquetas en formato sklearn (un número para cada punto)\n",
        "        labels = np.zeros(len(data_array), dtype=int)\n",
        "        for cluster_idx, cluster in enumerate(clusters):\n",
        "            for point_idx in cluster:\n",
        "                labels[point_idx] = cluster_idx\n",
        "        \n",
        "        # Calcular métricas\n",
        "        metrics = self.calcular_metricas(labels)\n",
        "        print(f\"Métricas para K-Medoids (n_clusters={n_clusters}, metric={metric}): {metrics}\")\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "    def hac(self, n_clusters=3, method='ward'):\n",
        "        self.__byebye_object_values()\n",
        "        data = self.__df\n",
        "        linkage_matrix = linkage(data, method=method)\n",
        "        labels = fcluster(linkage_matrix, t=n_clusters, criterion='maxclust')\n",
        "        metrics = self.calcular_metricas(labels)\n",
        "        print(f\"Métricas para HAC (n_clusters={n_clusters}, method={method}): {metrics}\")\n",
        "        return metrics\n",
        "\n",
        "    def umap_model(self, n_components=2, n_neighbors=15):\n",
        "        self.__byebye_object_values()\n",
        "        data = self.__df\n",
        "        modelo_umap = UMAP(n_components=n_components, n_neighbors=n_neighbors)\n",
        "        components = modelo_umap.fit_transform(data)\n",
        "        kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "        labels = kmeans.fit_predict(components)\n",
        "        metrics = self.calcular_metricas(labels)\n",
        "        print(f\"Métricas para UMAP (n_components={n_components}, n_neighbors={n_neighbors}): {metrics}\")\n",
        "        return metrics\n",
        "\n",
        "    def comparar_algoritmos(self, n_clusters):\n",
        "\n",
        "        if self.__df.isnull().any().any():\n",
        "          print(\"El DataFrame contiene valores nulos. Se eliminarán automáticamente para continuar.\")\n",
        "          self.__df.dropna(inplace=True)\n",
        "\n",
        "        print(\"\\nEjecutando K-Means...\")\n",
        "        kmeans_metrics = self.kmeans(n_clusters)\n",
        "\n",
        "        print(\"\\nEjecutando K-Medoids...\")\n",
        "        kmedoids_metrics = self.k_medoids(n_clusters)\n",
        "\n",
        "        print(\"\\nEjecutando HAC...\")\n",
        "        hac_metrics = self.hac(n_clusters=n_clusters)\n",
        "\n",
        "        print(\"\\nEjecutando UMAP...\")\n",
        "        umap_metrics = self.umap_model(n_components=2, n_neighbors=15)\n",
        "\n",
        "        resultados = pd.DataFrame({\n",
        "            \"K-Means\": kmeans_metrics,\n",
        "            \"K-Medoids\": kmedoids_metrics,\n",
        "            \"HAC\": hac_metrics,\n",
        "            \"UMAP\": umap_metrics\n",
        "        }).T\n",
        "\n",
        "        print(\"\\nComparación de Algoritmos:\")\n",
        "        print(resultados)\n",
        "        return resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grQ-5IXLjR-7"
      },
      "outputs": [],
      "source": [
        "class Supervisado(EDA):\n",
        "    def __init__(self, datos_eda):\n",
        "        # La clase ya utiliza el df procesado en la clase EDA\n",
        "        df = datos_eda.get_df()\n",
        "        super().__init__()\n",
        "        self.__df = df\n",
        "\n",
        "    @property\n",
        "    def df(self):\n",
        "        return self.__df\n",
        "\n",
        "    @df.setter\n",
        "    def df(self, p_df):\n",
        "        self.__df = p_df\n",
        "\n",
        "#-----------------Cosas del split----------------------------\n",
        "\n",
        "    def obtener_datos_split(self):\n",
        "        \"\"\"\n",
        "        Solicita al usuario el porcentaje de datos para entrenamiento.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            try:\n",
        "                porcentaje = float(input(\"Introduce el porcentaje para el conjunto de entrenamiento: \"))\n",
        "                if 0 < porcentaje < 100:\n",
        "                    return porcentaje / 100\n",
        "                else:\n",
        "                    print(\"El porcentaje debe estar entre 1 y 99.\")\n",
        "            except ValueError:\n",
        "                print(\"Número no válido, use la mente.\")\n",
        "\n",
        "    def split_df(self, target_column, test_size=None, random_state=42):\n",
        "      \"\"\"\n",
        "      Divide el dataframe en conjuntos de train y test.\n",
        "\n",
        "      Parametros:\n",
        "      - target_column: str -> Nombre de la columna objetivo (y).\n",
        "      - test_size: float -> Proporcion del conjunto de prueba (si no se da un dato, se calcula del porcentaje ingresado).\n",
        "      - random_state: int -> Semilla para la aleatorización.\n",
        "\n",
        "      Returns:\n",
        "      - X_train, X_test, y_train, y_test: Conjuntos divididos y preprocesados.\n",
        "      \"\"\"\n",
        "      if test_size is None:\n",
        "          # Si no se proporciona test_size, solicita al usuario el porcentaje\n",
        "          test_size = 1 - self.obtener_datos_split()\n",
        "\n",
        "      while True:\n",
        "          try:\n",
        "              # Separar las características (X) y la variable objetivo (y)\n",
        "              X = self.__df.drop(columns=[target_column])\n",
        "              y = self.__df[target_column]\n",
        "              break  # Salir del bucle si no hay errores\n",
        "          except KeyError:\n",
        "              print(f\"La columna '{target_column}' no existe. Intente nuevamente.\")\n",
        "              print(\"Columnas disponibles:\")\n",
        "              print(self.check_data_types())\n",
        "              target_column = input(\"Ingrese el nombre correcto de la columna objetivo: \")\n",
        "\n",
        "      # Preprocesar características (X), convertir variables categóricas a One-Hot Encoding\n",
        "      import pandas as pd\n",
        "      X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "      # Verificar si la variable objetivo (y) es categórica y necesita codificación\n",
        "      if y.dtypes == 'object' or y.dtypes.name == 'category':\n",
        "          from sklearn.preprocessing import LabelEncoder\n",
        "          le = LabelEncoder()\n",
        "          y = le.fit_transform(y)\n",
        "\n",
        "      # Realizar el split\n",
        "      X_train, X_test, y_train, y_test = train_test_split(\n",
        "          X, y, test_size=test_size, random_state=random_state\n",
        "      )\n",
        "\n",
        "      print(f\"Datos divididos:\\n- Entrenamiento: {X_train.shape[0]} filas\\n- Prueba: {X_test.shape[0]} filas\")\n",
        "      return X_train, X_test, y_train, y_test\n",
        "\n",
        "#-----------------Evaluacion de modelos----------------------------\n",
        "    def calcular_metricas(self, modelo, X_test, y_test, predicciones, modelo_nombre):\n",
        "      \"\"\"\n",
        "      Calcula las métricas de evaluación del modelo y guarda los resultados en un diccionario.\n",
        "\n",
        "      Parametros:\n",
        "      - modelo: El modelo en uso\n",
        "      - X_test: Datos de entrenamiento\n",
        "      - y_test: Datos de prueba\n",
        "      - predicciones: Predicciones del modelo\n",
        "      - modelo_nombre: Nombre del modelo\n",
        "\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de evaluación.\n",
        "      \"\"\"\n",
        "      mse = mean_squared_error(y_test, predicciones)\n",
        "      r2 = r2_score(y_test, predicciones)\n",
        "      mae = mean_absolute_error(y_test, predicciones)\n",
        "      rmse = np.sqrt(mse)\n",
        "      tolerancia = 0.1  # 10% de tolerancia\n",
        "      precision_global = np.mean(np.abs(y_test - predicciones) <= (tolerancia * y_test)) * 100\n",
        "\n",
        "      resultados = {\n",
        "          'modelo': modelo_nombre,\n",
        "          'MSE': mse,\n",
        "          'R2': r2,\n",
        "          'MAE': mae,\n",
        "          'RMSE': rmse,\n",
        "          'precision_global': precision_global,\n",
        "          #'predicciones': predicciones.tolist(),\n",
        "          #'valores_reales': y_test.tolist()\n",
        "      }\n",
        "      return resultados\n",
        "\n",
        "    def calcular_metricas_clasificacion(self, modelo, X_test, y_test, predicciones, modelo_nombre):\n",
        "      \"\"\"\n",
        "      Calcula las métricas de evaluación para modelos de clasificación y guarda los resultados en un diccionario.\n",
        "      \"\"\"\n",
        "      from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "      accuracy = accuracy_score(y_test, predicciones)\n",
        "      precision = precision_score(y_test, predicciones, average='weighted')\n",
        "      recall = recall_score(y_test, predicciones, average='weighted')\n",
        "      f1 = f1_score(y_test, predicciones, average='weighted')\n",
        "\n",
        "      return {\n",
        "          'modelo': modelo_nombre,\n",
        "          'accuracy': accuracy,\n",
        "          'precision': precision,\n",
        "          'recall': recall,\n",
        "          'f1_score': f1\n",
        "      }\n",
        "\n",
        "#------------------------Regression Models--------------------------------------------------------------\n",
        "\n",
        "    def regre_lineal_simple(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza una Regresión Lineal Simple y calcula múltiples métricas de rendimiento.\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de rendimiento del modelo\n",
        "      \"\"\"\n",
        "      print(\"Iniciando Regresión Lineal Simple...\")\n",
        "      modelo = LinearRegression()\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "      return self.calcular_metricas(modelo, X_test, y_test, predicciones, 'Regresión Lineal Simple')\n",
        "\n",
        "    def regre_svm(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza una Support Vector Machine y calcula múltiples métricas de rendimiento.\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de rendimiento del modelo\n",
        "      \"\"\"\n",
        "      print(\"Iniciando Support Vector Machine (SVM)...\")\n",
        "      from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "      # Escalar los datos\n",
        "      scaler = StandardScaler()\n",
        "      X_train_scaled = scaler.fit_transform(X_train)\n",
        "      X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "      modelo = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
        "      modelo.fit(X_train_scaled, y_train)\n",
        "      predicciones = modelo.predict(X_test_scaled)\n",
        "\n",
        "      return self.calcular_metricas(modelo, X_test_scaled, y_test, predicciones, 'Support Vector Machine')\n",
        "\n",
        "\n",
        "    def regre_regridge(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un Regresión Ridge y calcula múltiples métricas de rendimiento.\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de rendimiento del modelo\n",
        "      \"\"\"\n",
        "      print(\"Iniciando Regresión Ridge...\")\n",
        "      modelo = Ridge(alpha = 1.0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "      return self.calcular_metricas(modelo, X_test, y_test, predicciones, 'Regresión Ridge')\n",
        "\n",
        "    def regre_decisionTree(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un Decision Tree Regressor y calcula múltiples métricas de rendimiento.\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de rendimiento del modelo\n",
        "      \"\"\"\n",
        "      print(\"Iniciando DecisionTreeRegressor..\")\n",
        "      modelo = DecisionTreeRegressor(random_state=0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "      return self.calcular_metricas(modelo, X_test, y_test, predicciones, 'Decision Tree Regressor')\n",
        "\n",
        "    def regre_randomforest(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un Random Forest Regressor y calcula múltiples métricas de rendimiento.\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de rendimiento del modelo\n",
        "      \"\"\"\n",
        "      print(\"Iniciando RandomForest Regressor..\")\n",
        "      modelo = RandomForestRegressor(max_depth=2, random_state=0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "      return self.calcular_metricas(modelo, X_test, y_test, predicciones, 'Random Forest Regressor')\n",
        "\n",
        "    def regre_gradient_boosting(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un Grandient Boostsing Regressor y calcula múltiples métricas de rendimiento.\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de rendimiento del modelo\n",
        "      \"\"\"\n",
        "      print(\"Iniciando Grandient Boostsing Regressor..\")\n",
        "      modelo = GradientBoostingRegressor(random_state=0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "      return self.calcular_metricas(modelo, X_test, y_test, predicciones, 'Grandient Boostsing Regressor')\n",
        "\n",
        "    def regre_xgboost(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un XGBoost Regressor y calcula múltiples métricas de rendimiento.\n",
        "      Returns:\n",
        "      - resultados: Diccionario con métricas de rendimiento del modelo\n",
        "      \"\"\"\n",
        "      print(\"Iniciando XGBoost Regressor..\")\n",
        "      modelo = GradientBoostingRegressor(random_state=0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "      return self.calcular_metricas(modelo, X_test, y_test, predicciones, 'XGBoost Regressor')\n",
        "\n",
        "#------------------------Classification Models--------------------------------------------------------------\n",
        "\n",
        "    def classi_decision_tree(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un modelo de clasificación usando Árbol de Decisión y calcula métricas de rendimiento.\n",
        "      \"\"\"\n",
        "      print(\"Iniciando Decision Tree Classifier...\")\n",
        "      from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "      modelo = DecisionTreeClassifier(random_state=0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "\n",
        "      return self.calcular_metricas_clasificacion(modelo, X_test, y_test, predicciones, 'Decision Tree')\n",
        "\n",
        "    def classi_knn(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un modelo de clasificación usando K-Nearest Neighbors y calcula métricas de rendimiento.\n",
        "      \"\"\"\n",
        "      print(\"Iniciando K-Nearest Neighbors Classifier...\")\n",
        "      from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "      modelo = KNeighborsClassifier()\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "\n",
        "      return self.calcular_metricas_clasificacion(modelo, X_test, y_test, predicciones, 'K-Nearest Neighbors')\n",
        "\n",
        "    def classi_random_forest(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un modelo de clasificación usando Random Forest y calcula métricas de rendimiento.\n",
        "      \"\"\"\n",
        "      print(\"Iniciando Random Forest Classifier...\")\n",
        "      from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "      modelo = RandomForestClassifier(random_state=0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "\n",
        "      return self.calcular_metricas_clasificacion(modelo, X_test, y_test, predicciones, 'Random Forest')\n",
        "\n",
        "    def classi_adaboost(self, X_train, X_test, y_train, y_test):\n",
        "      \"\"\"\n",
        "      Realiza un modelo de clasificación usando AdaBoost y calcula métricas de rendimiento.\n",
        "      \"\"\"\n",
        "      print(\"Iniciando AdaBoost Classifier...\")\n",
        "      from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "      modelo = AdaBoostClassifier(random_state=0)\n",
        "      modelo.fit(X_train, y_train)\n",
        "      predicciones = modelo.predict(X_test)\n",
        "\n",
        "      return self.calcular_metricas_clasificacion(modelo, X_test, y_test, predicciones, 'AdaBoost')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUAM4Lsdna5a"
      },
      "outputs": [],
      "source": [
        "class Start:\n",
        "    def __init__(self):\n",
        "        self.eda = None\n",
        "        self.supervisado = None\n",
        "        self.no_supervisado = None\n",
        "        self.split_data = None\n",
        "\n",
        "\n",
        "    def mostrar_menu(self):\n",
        "        while True:\n",
        "            print(\"\\n--- Menú Principal ---\")\n",
        "            print(\"1. 📁 Carga de datos en formato CSV y completar EDA\")\n",
        "            print(\"2. 🪐 Ejecutar modelo\")\n",
        "            print(\"3. 🛑 Salir\")\n",
        "            opcion = input(\"Seleccione una opción: \")\n",
        "\n",
        "            if opcion == \"1\":\n",
        "                self.datos_eda()\n",
        "            elif opcion == \"2\":\n",
        "                self.models_menu()\n",
        "            elif opcion == \"3\":\n",
        "                print(\"Saliendo del programa...\")\n",
        "                break\n",
        "            else:\n",
        "                print(\"Opción no válida. Intente de nuevo.\")\n",
        "\n",
        "    def models_menu(self):\n",
        "      while True:\n",
        "        print(\"\\n--- ¿Qué problema necesita resolver? ---\")\n",
        "        print(\"1. 🔍 Clasificación: Asigne etiquetas a sus datos\")\n",
        "        print(\"2. 📈 Regresión: Prediga valores continuos\")\n",
        "        print(\"3. 🧩 Aprendizaje No Supervisado: Descubra patrones ocultos\")\n",
        "        print(\"4. 🛑 Volver al menú principal\")\n",
        "        opcion = input(\"Seleccione una opción: \")\n",
        "\n",
        "        # Resetear split_data antes de cambiar de modelo\n",
        "        self.split_data = None\n",
        "        self.supervisado = None\n",
        "\n",
        "        if opcion == \"1\":\n",
        "            self.classi_modelos()\n",
        "        elif opcion == \"2\":\n",
        "            self.regre_modelos()\n",
        "        elif opcion == \"3\":\n",
        "                if self.eda and not self.eda.get_df().empty:\n",
        "                  self.no_supervisado = NoSupervisado(self.eda)\n",
        "                  n_clusters = int(input(\"Ingrese el número de clusters: \"))\n",
        "                  self.no_supervisado.comparar_algoritmos(n_clusters=n_clusters)\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos para poder realizar aprendizaje no supervisado.\")\n",
        "        elif opcion == \"4\":\n",
        "            print(\"Saliendo del programa...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Opción no válida. Intente de nuevo.\")\n",
        "\n",
        "    def datos_eda(self):\n",
        "        while True:\n",
        "            print(\"\\n ----EDA----\")\n",
        "            print(\"1. 📂 Carga de datos\")\n",
        "            print(\"2. 🔍 Mostrar head del DataFrame\")\n",
        "            print(\"3. 📊 Revisar los tipos de datos\")\n",
        "            print(\"4. ✂️ Eliminar columnas\")\n",
        "            print(\"5. 🧹 Eliminar valores NULOS\")\n",
        "            print(\"6. ⚠️ Detectar valores atipicos\")\n",
        "            print(\"7. 📈 Graficar relación entre dos variables\")\n",
        "            print(\"8. 📉 Graficar histograma\")\n",
        "            print(\"9. 🌡 HeatMap: Generar mapa de calor\")\n",
        "            print(\"0. 🛑 Volver al menú principal\")\n",
        "            opcion = input(\"Seleccione una opción: \")\n",
        "\n",
        "            if opcion == \"1\":\n",
        "                my_data = input(\"¿Cómo se llama el CSV? \")\n",
        "                try:\n",
        "                    self.eda = EDA(file=my_data)\n",
        "                    print(\"Instancia de EDA creada y datos cargados exitosamente.\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error al cargar los datos: {e}\")\n",
        "            elif opcion == \"2\":\n",
        "                if self.eda:\n",
        "                    print(self.eda.head_df())\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"3\":\n",
        "                if self.eda:\n",
        "                    print(self.eda.check_data_types())\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"4\":\n",
        "                if self.eda:\n",
        "                    columnas = input(\"Ingrese los nombres de las columnas a eliminar, separadas por comas: \").split(',')\n",
        "                    columnas = [col.strip() for col in columnas]\n",
        "                    try:\n",
        "                        self.eda.drop_irrelevant_columns(columnas)\n",
        "                        print(f\"Columnas eliminadas: {', '.join(columnas)}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error al eliminar columnas: {e}\")\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"5\":\n",
        "                if self.eda:\n",
        "                    self.eda.drop_missing_values()\n",
        "                    print(\"Valores nulos eliminados.\")\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"6\":\n",
        "                if self.eda:\n",
        "                    print(self.eda.detect_outliers())\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"7\":\n",
        "                if self.eda:\n",
        "                    print(\"\\n ***Variables disponibles***\")\n",
        "                    print(self.eda.check_data_types())\n",
        "                    col1 = input(\"Ingrese el nombre de la primera variable: \")\n",
        "                    col2 = input(\"Ingrese el nombre de la segunda variable: \")\n",
        "                    try:\n",
        "                        self.eda.plot_scatter(col1, col2)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error al graficar: {e}\")\n",
        "                        break\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"8\":\n",
        "                if self.eda:\n",
        "                    print(\"\\n ***Variables disponibles***\")\n",
        "                    print(self.eda.check_data_types())\n",
        "                    histogram_col = input(\"Ingrese el nombre de una variable a graficar: \")\n",
        "                    try:\n",
        "                        self.eda.plot_histogram(histogram_col)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error al graficar: {e}\")\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"9\":\n",
        "                if self.eda:\n",
        "                    self.eda.plot_heatmap()\n",
        "                    print(\"El programa se detendrá después de mostrar el gráfico.\")\n",
        "                    exit()\n",
        "                else:\n",
        "                    print(\"Primero cargue los datos.\")\n",
        "            elif opcion == \"0\":\n",
        "                break\n",
        "            else:\n",
        "                print(\"Opción no válida. Intente de nuevo.\")\n",
        "\n",
        "    def regre_modelos(self):\n",
        "      if self.supervisado is None:\n",
        "          if self.eda:\n",
        "              self.supervisado = Supervisado(self.eda)\n",
        "          else:\n",
        "              print(\"Primero debe cargar los datos\")\n",
        "              return\n",
        "\n",
        "      if self.split_data is None:\n",
        "          print(\"\\n ***Variables disponibles***\")\n",
        "          print(self.eda.check_data_types())\n",
        "          target_column = input(\"\\n Ingrese el nombre de la columna objetivo: \")\n",
        "          self.split_data = self.supervisado.split_df(target_column)\n",
        "\n",
        "      X_train, X_test, y_train, y_test = self.split_data\n",
        "\n",
        "      modelos = [\n",
        "          self.supervisado.regre_lineal_simple,\n",
        "          self.supervisado.regre_svm,\n",
        "          self.supervisado.regre_regridge,\n",
        "          self.supervisado.regre_decisionTree,\n",
        "          self.supervisado.regre_randomforest,\n",
        "          self.supervisado.regre_gradient_boosting,\n",
        "          self.supervisado.regre_xgboost\n",
        "      ]\n",
        "\n",
        "      resultados = []\n",
        "      for modelo in modelos:\n",
        "          resultados.append(modelo(X_train, X_test, y_train, y_test))\n",
        "\n",
        "      print(\"\\n--- Resultados del Benchmarking ---\")\n",
        "      for resultado in resultados:\n",
        "          print(f\"{resultado['modelo']}: R2={resultado['R2']:.4f}, RMSE={resultado['RMSE']:.4f}, MAE={resultado['MAE']:.4f}\")\n",
        "\n",
        "      # Opción de graficar resultados\n",
        "      graficar = input(\"\\n¿Desea graficar los resultados? (S/N): \").strip().upper()\n",
        "      if graficar == 'S':\n",
        "        # Preparar datos para la gráfica\n",
        "        nombres_modelos = [resultado['modelo'] for resultado in resultados]\n",
        "        r2_scores = [resultado['R2'] for resultado in resultados]\n",
        "        rmse_scores = [resultado['RMSE'] for resultado in resultados]\n",
        "        mae_scores = [resultado['MAE'] for resultado in resultados]\n",
        "\n",
        "        # Crear la gráfica de barras comparativa\n",
        "        plt.figure(figsize=(15, 6))\n",
        "\n",
        "        # Gráfica de R2\n",
        "        plt.subplot(1, 3, 1)\n",
        "        bars1 = plt.bar(nombres_modelos, r2_scores)\n",
        "        plt.title('R2 Scores')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylabel('R2')\n",
        "        # Añadir valores en las barras\n",
        "        for bar in bars1:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                     f'{height:.4f}',\n",
        "                     ha='center', va='bottom', rotation=0)\n",
        "\n",
        "        # Gráfica de RMSE\n",
        "        plt.subplot(1, 3, 2)\n",
        "        bars2 = plt.bar(nombres_modelos, rmse_scores)\n",
        "        plt.title('Root Mean Squared Error')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylabel('RMSE')\n",
        "        # Añadir valores en las barras\n",
        "        for bar in bars2:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                     f'{height:.4f}',\n",
        "                     ha='center', va='bottom', rotation=0)\n",
        "\n",
        "        # Gráfica de MAE\n",
        "        plt.subplot(1, 3, 3)\n",
        "        bars3 = plt.bar(nombres_modelos, mae_scores)\n",
        "        plt.title('Mean Absolute Error')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.ylabel('MAE')\n",
        "        # Añadir valores en las barras\n",
        "        for bar in bars3:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                     f'{height:.4f}',\n",
        "                     ha='center', va='bottom', rotation=0)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        exit()\n",
        "\n",
        "    def classi_modelos(self):\n",
        "        if graficar == 'S':\n",
        "          # Preparar datos para la gráfica\n",
        "          nombres_modelos = [resultado['modelo'] for resultado in resultados]\n",
        "          accuracy_scores = [resultado['accuracy'] for resultado in resultados]\n",
        "          precision_scores = [resultado['precision'] for resultado in resultados]\n",
        "          recall_scores = [resultado['recall'] for resultado in resultados]\n",
        "          f1_scores = [resultado['f1_score'] for resultado in resultados]\n",
        "\n",
        "          # Crear la gráfica de barras comparativa\n",
        "          plt.figure(figsize=(15, 6))\n",
        "\n",
        "          # Gráfica de Accuracy\n",
        "          plt.subplot(1, 4, 1)\n",
        "          bars1 = plt.bar(nombres_modelos, accuracy_scores)\n",
        "          plt.title('Accuracy')\n",
        "          plt.xticks(rotation=45, ha='right')\n",
        "          plt.ylabel('Accuracy')\n",
        "          # Añadir valores en las barras\n",
        "          for bar in bars1:\n",
        "              height = bar.get_height()\n",
        "              plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{height:.4f}',\n",
        "                      ha='center', va='bottom', rotation=0)\n",
        "\n",
        "          # Gráfica de Precision\n",
        "          plt.subplot(1, 4, 2)\n",
        "          bars2 = plt.bar(nombres_modelos, precision_scores)\n",
        "          plt.title('Precision')\n",
        "          plt.xticks(rotation=45, ha='right')\n",
        "          plt.ylabel('Precision')\n",
        "          # Añadir valores en las barras\n",
        "          for bar in bars2:\n",
        "              height = bar.get_height()\n",
        "              plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{height:.4f}',\n",
        "                      ha='center', va='bottom', rotation=0)\n",
        "\n",
        "          # Gráfica de Recall\n",
        "          plt.subplot(1, 4, 3)\n",
        "          bars3 = plt.bar(nombres_modelos, recall_scores)\n",
        "          plt.title('Recall')\n",
        "          plt.xticks(rotation=45, ha='right')\n",
        "          plt.ylabel('Recall')\n",
        "          # Añadir valores en las barras\n",
        "          for bar in bars3:\n",
        "              height = bar.get_height()\n",
        "              plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{height:.4f}',\n",
        "                      ha='center', va='bottom', rotation=0)\n",
        "\n",
        "          # Gráfica de F1-Score\n",
        "          plt.subplot(1, 4, 4)\n",
        "          bars4 = plt.bar(nombres_modelos, f1_scores)\n",
        "          plt.title('F1-Score')\n",
        "          plt.xticks(rotation=45, ha='right')\n",
        "          plt.ylabel('F1-Score')\n",
        "          # Añadir valores en las barras\n",
        "          for bar in bars4:\n",
        "              height = bar.get_height()\n",
        "              plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                      f'{height:.4f}',\n",
        "                      ha='center', va='bottom', rotation=0)\n",
        "\n",
        "          plt.tight_layout()\n",
        "          plt.show()\n",
        "          exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWprvJMPYo_D"
      },
      "source": [
        "Ejecucion del programa con estructura pythonica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pkb3yN8QYtEw",
        "outputId": "42c5f0ac-d091-4376-bbe5-a985977f1af8"
      },
      "outputs": [],
      "source": [
        "# Ejecución del menú principal\n",
        "if __name__ == \"__main__\":\n",
        "    start = Start()\n",
        "    start.mostrar_menu()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
